{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_1704\\2710358209.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  RRU_PL['AAU功耗[千瓦时]'] = pd.to_numeric(RRU_PL['AAU功耗[千瓦时]'], errors='coerce').round(4).fillna(0)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_1704\\2710358209.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  BBU_PL[col] = pd.to_numeric(BBU_PL[col], errors='coerce').round(4).fillna(0)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_1704\\2710358209.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  BBU_PL[col] = pd.to_numeric(BBU_PL[col], errors='coerce').fillna(0).astype(int)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_1704\\2710358209.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  BBU_PL[col] = pd.to_numeric(BBU_PL[col], errors='coerce').fillna(0).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to gdf_RAC.csv\n",
      "DataFrame exported to df_KPI.csv\n",
      "DataFrame exported to BS_PL.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import re\n",
    "\n",
    "# Unified data directories\n",
    "Datadir = r'C:\\Users\\Administrator\\Documents\\MnewData'\n",
    "output_path = r'C:\\Users\\Administrator\\PYMo\\Data'\n",
    "\n",
    "def list_csv_files(directory, keyword):\n",
    "    \"\"\"List CSV files in the specified directory that contain the keyword.\"\"\"\n",
    "    return [file for file in os.listdir(directory) if keyword in file and file.endswith('.csv')]\n",
    "\n",
    "def read_and_process_files(directory, keyword, columns=None, encoding='gbk'):\n",
    "    \"\"\"Read and process CSV files, returning a concatenated DataFrame.\"\"\"\n",
    "    files = list_csv_files(directory, keyword)\n",
    "    dfs = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(directory, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding=encoding, usecols=columns, na_values=[\"n/a\", \"na\", \"-\"]) if columns else pd.read_csv(file_path, encoding=encoding, skiprows=2, header=0, na_values=[\"n/a\", \"na\", \"-\"])\n",
    "            dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file {file}: {e}\")\n",
    "    return pd.concat(dfs, ignore_index=True).drop_duplicates() if dfs else pd.DataFrame()\n",
    "\n",
    "def read_hubei_map_files(directory, filename):\n",
    "    \"\"\"Read the Hubei map file.\"\"\"\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    return gpd.read_file(file_path)\n",
    "\n",
    "def split_field(field, is_rru):\n",
    "    if is_rru:\n",
    "        match = re.match(r'(.+)\\(gNB=(\\d+),invRRU=(\\d+)\\)', field)\n",
    "        return (match.group(2), match.group(3)) if match else (None, None)\n",
    "    else:\n",
    "        match = re.match(r'(.+)\\(gNB=(\\d+)\\)', field)\n",
    "        return (match.group(1), match.group(2)) if match else (None, None)\n",
    "\n",
    "def process_rru_pl(RRU_PL):\n",
    "    \"\"\"Process RRU_PL DataFrame.\"\"\"\n",
    "    RRU_PL[['BBUID', 'RRUID']] = RRU_PL['对象'].apply(lambda x: pd.Series(split_field(x, is_rru=True)))\n",
    "    RRU_PL = RRU_PL[['BBUID', 'RRUID', '开始时间', 'AAU功耗[千瓦时]']]\n",
    "    RRU_PL['AAU功耗[千瓦时]'] = pd.to_numeric(RRU_PL['AAU功耗[千瓦时]'], errors='coerce').round(4).fillna(0)\n",
    "    return RRU_PL\n",
    "\n",
    "def process_bbu_pl(BBU_PL):\n",
    "    \"\"\"Process BBU_PL DataFrame.\"\"\"\n",
    "    BBU_PL[['BBU名称', 'BBUID']] = BBU_PL['对象'].apply(lambda x: pd.Series(split_field(x, is_rru=False)))\n",
    "    BBU_PL['站型'] = BBU_PL['BBU名称'].apply(lambda x: '宏站' if 'D5H' in x else ('微站' if 'D5M' in x else ('室分' if 'D5S' in x else '未知')))\n",
    "    BBU_PL = BBU_PL[['BBU名称', 'BBUID', '站型', '开始时间', 'BBU功耗[千瓦时]', 'gNB基站CPU平均负荷(R1056_001)[%]', 'gNB基站CPU峰值负荷(R1056_002)[%]', 'BBU功耗(R1054_001)[W]']]\n",
    "    \n",
    "    for col in ['BBU功耗[千瓦时]', 'BBU功耗(R1054_001)[W]']:\n",
    "        BBU_PL[col] = pd.to_numeric(BBU_PL[col], errors='coerce').round(4).fillna(0)\n",
    "    \n",
    "    for col in ['gNB基站CPU平均负荷(R1056_001)[%]', 'gNB基站CPU峰值负荷(R1056_002)[%]']:\n",
    "        BBU_PL[col] = pd.to_numeric(BBU_PL[col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    return BBU_PL\n",
    "\n",
    "def process_rf_ap_cp(df_ap, df_rf, df_cp, gdf):\n",
    "    \"\"\"Merge RF, AP, and CP data and perform spatial join.\"\"\"\n",
    "    df_rfap = pd.merge(df_ap, df_rf, on=['网元标识', '射频单元编号'], how='inner')\n",
    "    df_rfap = df_rfap[['网元标识', '小区本地ID', '射频单元编号', 'Longitude', 'Latitude']]  # Select and rename columns\n",
    "\n",
    "    df_rac = pd.merge(df_rfap, df_cp, on=['网元标识', '小区本地ID'], how='inner')\n",
    "    df_rac = df_rac[['网元标识', '小区本地ID', 'BBU机房', '基站名称', '小区名称', '工作频段', 'Longitude', 'Latitude']]  # Select and rename columns\n",
    "\n",
    "    geometry = [Point(xy) for xy in zip(df_rac['Longitude'], df_rac['Latitude'])]\n",
    "    df_rac = gpd.GeoDataFrame(df_rac, geometry=geometry)\n",
    "    # 设置 CRS\n",
    "    if df_rac.crs is None:\n",
    "        df_rac = df_rac.set_crs(gdf.crs)\n",
    "\n",
    "    return gpd.sjoin(df_rac, gdf, how='inner', predicate='within')\n",
    "\n",
    "def process_bs_pl(BBU_PL, RRU_PL):\n",
    "    \"\"\"Process BS_PL data.\"\"\"\n",
    "    antenna_count = RRU_PL.groupby(['BBUID', '开始时间'])['RRUID'].nunique().reset_index(name='天线数量')\n",
    "    total_rru_power = RRU_PL.groupby(['BBUID', '开始时间'])['AAU功耗[千瓦时]'].sum().reset_index(name='RRU总功耗')\n",
    "\n",
    "    BBU_PL = pd.merge(BBU_PL, antenna_count, on=['BBUID', '开始时间'], how='left')\n",
    "    BBU_PL = pd.merge(BBU_PL, total_rru_power, on=['BBUID', '开始时间'], how='left')\n",
    "    BBU_PL['频段'] = BBU_PL['BBU名称'].apply(lambda x: '700M' if '700M' in x else '2.6G')\n",
    "\n",
    "    return BBU_PL[['BBU名称', 'BBUID', '天线数量', 'RRU总功耗', '频段']]\n",
    "\n",
    "def save_dataframe_to_csv(df, filename):\n",
    "    \"\"\"Save DataFrame to CSV file.\"\"\"\n",
    "    df.to_csv(os.path.join(output_path, filename), index=False, encoding='utf-8-sig')\n",
    "    print(f\"DataFrame exported to {filename}\")\n",
    "\n",
    "def read_and_process_kpi_files(directory, keyword='DT_PowerBI指标通报计数器_', file_extension='.csv'):\n",
    "    \"\"\"Read and process KPI files.\"\"\"\n",
    "    def load_csv_files(directory, keyword, file_extension):\n",
    "        files = [file for file in os.listdir(directory) if keyword in file and file.lower().endswith(file_extension)]\n",
    "        dfs = []\n",
    "        for file in files:\n",
    "            file_path = os.path.join(directory, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, skiprows=2, header=0, encoding='cp936', na_values=[\"n/a\", \"na\", \"-\"])\n",
    "                df.columns = df.columns.str.replace(' ', '')  # 去除列名中的空格\n",
    "                dfs.append(df)\n",
    "            except (UnicodeDecodeError, Exception) as e:\n",
    "                print(f\"读取文件时发生错误：{e}\")\n",
    "        return dfs\n",
    "\n",
    "    def process_dates(df, date_columns):\n",
    "        for column in date_columns:\n",
    "            df[column] = pd.to_datetime(df[column].astype(str).str.split().str[0], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "        return df\n",
    "\n",
    "    def split_columns(df):\n",
    "        df[[\"小区名称\", \"Other\"]] = df[\"对象\"].str.split('\\\\(g', n=1, expand=True)\n",
    "        df[[\"NB\", \"nrCellCfg\"]] = df[\"Other\"].str.split(',', n=1, expand=True)\n",
    "        df[\"NB\"] = df[\"NB\"].str.lstrip('NB=')\n",
    "        df[\"nrCellCfg\"] = df[\"nrCellCfg\"].str.lstrip('nrCellCfg=').str.rstrip(')')\n",
    "        df.drop(columns=[\"对象\", \"Other\"], inplace=True)\n",
    "        return df\n",
    "\n",
    "    def convert_column_types(df, int_columns, float_columns):\n",
    "        df[int_columns] = df[int_columns].apply(pd.to_numeric, errors='coerce').fillna(0).astype(int)\n",
    "        df[float_columns] = df[float_columns].apply(pd.to_numeric, errors='coerce').fillna(0).round(2)\n",
    "        return df\n",
    "\n",
    "    def extract_code(column_name):\n",
    "        match = re.search(r'\\((.*?)\\)', column_name)\n",
    "        return match.group(1) if match else column_name\n",
    "\n",
    "    dfs = load_csv_files(directory, keyword, file_extension)\n",
    "    if not dfs:\n",
    "        print(\"没有成功读取任何文件，请检查文件路径和过滤条件。\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_kpi = pd.concat(dfs, ignore_index=True).drop_duplicates()\n",
    "\n",
    "    date_columns = ['开始时间', '结束时间']\n",
    "    df_kpi = process_dates(df_kpi, date_columns)\n",
    "\n",
    "    df_kpi = split_columns(df_kpi)\n",
    "\n",
    "    df_kpi['NB'] = df_kpi['NB'].astype(str)\n",
    "    df_kpi['nrCellCfg'] = df_kpi['nrCellCfg'].astype(str)\n",
    "\n",
    "    df_kpi['ID'] = df_kpi['NB'] + '_' + df_kpi['nrCellCfg']\n",
    "\n",
    "    new_order = df_kpi.columns[-3:].tolist() + df_kpi.columns[:-3].tolist()\n",
    "    df_kpi = df_kpi[new_order]\n",
    "\n",
    "    int_columns = df_kpi.loc[:, 'gNB请求释放的5QI为1的Flow数(R2035_003)[个]':'gNBRRC连接建立成功次数-moVideoCall(R1001_019)[次]'].columns\n",
    "    float_columns = ['5QI为1的平均Flow数(K1009_001)[个]', '5QI为2的平均Flow数(K1009_002)[个]']\n",
    "    df_kpi = convert_column_types(df_kpi, int_columns, float_columns)\n",
    "\n",
    "    df_kpi = df_kpi.drop(columns=['小区名称', 'Nr小区工作频段', '小区下行系统带宽(MHz)', '逻辑小区id'])\n",
    "\n",
    "    df_kpi['小区用户面RLCSDU上行尾包字节数(R1501_005)[0.01KByte]'] /= 100\n",
    "    df_kpi['小区用户面RLCSDU下行尾包字节数(R1501_006)[0.01KByte]'] /= 100\n",
    "\n",
    "    df_kpi.columns = df_kpi.columns.to_series().apply(extract_code)\n",
    "\n",
    "    return df_kpi\n",
    "\n",
    "# Read and process data\n",
    "df_AP = read_and_process_files(Datadir, '天线安装规划', ['网元标识', '远端射频单元编号', '本地小区标识1'])\n",
    "df_AP.columns = ['网元标识', '射频单元编号', '小区本地ID']  # Rename columns for df_AP\n",
    "\n",
    "gdffile = '湖北省村级边界.geojson'\n",
    "gdf = read_hubei_map_files(Datadir, gdffile)\n",
    "\n",
    "df_RF = read_and_process_files(Datadir, '射频单元规划', ['网元标识', '射频单元编号', '射频单元RRU安装经度', '射频单元RRU安装纬度'])\n",
    "df_RF.columns = ['网元标识', '射频单元编号', 'Longitude', 'Latitude']  # Rename columns for df_RF\n",
    "\n",
    "df_CP = read_and_process_files(Datadir, 'NR小区', ['网元标识', '网元名称', '小区本地ID', '小区友好名', 'Nr小区工作频段'])\n",
    "df_CP.rename(columns={'小区友好名': '小区名称', '网元名称': 'BBU机房'}, inplace=True)\n",
    "df_CP['工作频段'] = df_CP['Nr小区工作频段'].str.split('(').str[0]\n",
    "df_CP['基站名称'] = df_CP['小区名称'].str.replace(r'(-26.*|-07.*)', '', regex=True)\n",
    "df_CP = df_CP[['网元标识', 'BBU机房', '基站名称', '小区本地ID', '小区名称', '工作频段']]\n",
    "\n",
    "gdf_RAC = process_rf_ap_cp(df_AP, df_RF, df_CP, gdf)\n",
    "\n",
    "# Read BBU and RRU power consumption\n",
    "BBU_PL = read_and_process_files(Datadir, 'DT_BBU功耗_')\n",
    "RRU_PL = read_and_process_files(Datadir, 'DT_RRU功耗_')\n",
    "\n",
    "# Process RRU_PL and BBU_PL\n",
    "RRU_PL = process_rru_pl(RRU_PL)\n",
    "BBU_PL = process_bbu_pl(BBU_PL)\n",
    "\n",
    "# Process BS_PL\n",
    "BS_PL = process_bs_pl(BBU_PL, RRU_PL)\n",
    "\n",
    "# Process KPI file\n",
    "df_KPI = read_and_process_kpi_files(Datadir)\n",
    "\n",
    "# Save results\n",
    "save_dataframe_to_csv(gdf_RAC, 'gdf_RAC.csv')\n",
    "save_dataframe_to_csv(df_KPI, 'df_KPI.csv')\n",
    "save_dataframe_to_csv(BS_PL, 'BS_PL.csv')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
